{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 20\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load data\n",
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_1a</td>\n",
       "      <td>rice</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1b</td>\n",
       "      <td>candy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_1c</td>\n",
       "      <td>jam</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_1d</td>\n",
       "      <td>coffee</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_2a</td>\n",
       "      <td>vinegar</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id    label  label_enc\n",
       "0  train_1a     rice         17\n",
       "1  train_1b    candy          2\n",
       "2  train_1c      jam         11\n",
       "3  train_1d   coffee          6\n",
       "4  train_2a  vinegar         23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train['label_enc'] = le.fit_transform(train.label)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to read image\n",
    "def read_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (IM_WIDTH, IM_HEIGHT))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set path for images\n",
    "TRAIN_PATH = 'input/train_img/'\n",
    "TEST_PATH = 'input/test_img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3215/3215 [00:10<00:00, 304.00it/s]\n",
      "100%|██████████| 1732/1732 [00:05<00:00, 341.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_img, test_img = [],[]\n",
    "for img_path in tqdm(train['image_id'].values):\n",
    "    train_img.append(read_img(TRAIN_PATH + img_path + '.png'))\n",
    "\n",
    "for img_path in tqdm(test['image_id'].values):\n",
    "    test_img.append(read_img(TEST_PATH + img_path + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize images\n",
    "x_train = np.array(train_img, np.float32)\n",
    "x_test = np.array(test_img, np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3215, 299, 299, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(train.label_enc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3215, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer learning with Inception V3 \n",
    "#include_top=False excludes final FC layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## set model architechture \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(x) #new softmax layer\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch_size = 32 # tune it\n",
    "#epochs = 9 # increase it\n",
    "train_datagen =  ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(\n",
    "    x_train, y_train,\n",
    "    #target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=BAT_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., class_weight=\"auto\", steps_per_epoch=100, epochs=10)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 164s - loss: 5.7890 - acc: 0.1244   \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 160s - loss: 2.4246 - acc: 0.2804   \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 160s - loss: 2.0847 - acc: 0.3695   \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 133s - loss: 1.9069 - acc: 0.4118   \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 51s - loss: 1.7725 - acc: 0.4639    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 53s - loss: 1.6603 - acc: 0.4916    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 56s - loss: 1.5494 - acc: 0.5146    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 58s - loss: 1.5034 - acc: 0.5347    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 53s - loss: 1.4621 - acc: 0.5512    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 52s - loss: 1.4152 - acc: 0.5700    \n"
     ]
    }
   ],
   "source": [
    "history_tl = model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=NB_EPOCHS,\n",
    "    samples_per_epoch=x_train.shape[0],     \n",
    "    class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "     layer.trainable = False\n",
    "for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "     layer.trainable = True\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., class_weight=\"auto\", steps_per_epoch=100, epochs=10)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 76s - loss: 0.3245 - acc: 0.9159    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 76s - loss: 0.2894 - acc: 0.9309    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 79s - loss: 0.2885 - acc: 0.9303    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 84s - loss: 0.2837 - acc: 0.9280    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 78s - loss: 0.2981 - acc: 0.9202    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 83s - loss: 0.2684 - acc: 0.9306    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 79s - loss: 0.2753 - acc: 0.9271    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 81s - loss: 0.2582 - acc: 0.9418    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 89s - loss: 0.2418 - acc: 0.9443    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 83s - loss: 0.2569 - acc: 0.9365    \n"
     ]
    }
   ],
   "source": [
    "history_ft = model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=NB_EPOCHS,\n",
    "    steps_per_epoch=x_train.shape[0]// BAT_SIZE,    \n",
    "    class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1732, 256, 256, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## predict test data\n",
    "predictions = model.predict(preprocess_input(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get labels\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "pred_labels = le.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chocolate', 'chocolate', 'chocolate', ..., 'chocolate',\n",
       "       'chocolate', 'chocolate'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make submission\n",
    "sub = pd.DataFrame({'image_id':test.image_id, 'label':pred_labels})\n",
    "sub.to_csv('sub_Iv5.csv', index=False) ##70 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chocolate    1732\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
