{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 30\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load data\n",
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_1a</td>\n",
       "      <td>rice</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1b</td>\n",
       "      <td>candy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_1c</td>\n",
       "      <td>jam</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_1d</td>\n",
       "      <td>coffee</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_2a</td>\n",
       "      <td>vinegar</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id    label  label_enc\n",
       "0  train_1a     rice         17\n",
       "1  train_1b    candy          2\n",
       "2  train_1c      jam         11\n",
       "3  train_1d   coffee          6\n",
       "4  train_2a  vinegar         23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train['label_enc'] = le.fit_transform(train.label)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to read image\n",
    "def read_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (IM_WIDTH, IM_HEIGHT))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set path for images\n",
    "TRAIN_PATH = 'input/train_img/'\n",
    "TEST_PATH = 'input/test_img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3215/3215 [00:08<00:00, 375.72it/s]\n",
      "100%|██████████| 1732/1732 [00:04<00:00, 378.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_img, test_img = [],[]\n",
    "for img_path in tqdm(train['image_id'].values):\n",
    "    train_img.append(read_img(TRAIN_PATH + img_path + '.png'))\n",
    "\n",
    "for img_path in tqdm(test['image_id'].values):\n",
    "    test_img.append(read_img(TEST_PATH + img_path + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize images\n",
    "x_train = np.array(train_img, np.float32)\n",
    "x_test = np.array(test_img, np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3215, 299, 299, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(train.label_enc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3215, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transfer learning with Inception V3 \n",
    "#include_top=False excludes final FC layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IM_WIDTH, IM_HEIGHT, 3))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## set model architechture \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(x) #new softmax layer\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch_size = 32 # tune it\n",
    "#epochs = 9 # increase it\n",
    "train_datagen =  ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(\n",
    "    x_train, y_train,\n",
    "    #target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=BAT_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., class_weight=\"auto\", steps_per_epoch=100.46875, epochs=30)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "101/100 [==============================] - 58s - loss: 3.2800 - acc: 0.1340    \n",
      "Epoch 2/30\n",
      "101/100 [==============================] - 56s - loss: 2.3746 - acc: 0.2808    \n",
      "Epoch 3/30\n",
      "101/100 [==============================] - 46s - loss: 2.0682 - acc: 0.3699    \n",
      "Epoch 4/30\n",
      "101/100 [==============================] - 48s - loss: 1.9002 - acc: 0.4227    \n",
      "Epoch 5/30\n",
      "101/100 [==============================] - 45s - loss: 1.7616 - acc: 0.4517    \n",
      "Epoch 6/30\n",
      "101/100 [==============================] - 48s - loss: 1.6460 - acc: 0.4951    \n",
      "Epoch 7/30\n",
      "101/100 [==============================] - 45s - loss: 1.5709 - acc: 0.5254    \n",
      "Epoch 8/30\n",
      "101/100 [==============================] - 45s - loss: 1.5105 - acc: 0.5284    \n",
      "Epoch 9/30\n",
      "101/100 [==============================] - 46s - loss: 1.4529 - acc: 0.5618    \n",
      "Epoch 10/30\n",
      "101/100 [==============================] - 45s - loss: 1.4181 - acc: 0.5587    \n",
      "Epoch 11/30\n",
      "101/100 [==============================] - 45s - loss: 1.3714 - acc: 0.5755    \n",
      "Epoch 12/30\n",
      "101/100 [==============================] - 45s - loss: 1.3573 - acc: 0.5856    \n",
      "Epoch 13/30\n",
      "101/100 [==============================] - 48s - loss: 1.2848 - acc: 0.6023    \n",
      "Epoch 14/30\n",
      "101/100 [==============================] - 47s - loss: 1.2469 - acc: 0.6130    \n",
      "Epoch 15/30\n",
      "101/100 [==============================] - 45s - loss: 1.2671 - acc: 0.6090    \n",
      "Epoch 16/30\n",
      "101/100 [==============================] - 52s - loss: 1.2158 - acc: 0.6214    \n",
      "Epoch 17/30\n",
      "101/100 [==============================] - 45s - loss: 1.1919 - acc: 0.6322    \n",
      "Epoch 18/30\n",
      "101/100 [==============================] - 45s - loss: 1.1597 - acc: 0.6364    \n",
      "Epoch 19/30\n",
      "101/100 [==============================] - 45s - loss: 1.1288 - acc: 0.6364    \n",
      "Epoch 20/30\n",
      "101/100 [==============================] - 45s - loss: 1.1180 - acc: 0.6444    \n",
      "Epoch 21/30\n",
      "101/100 [==============================] - 45s - loss: 1.0900 - acc: 0.6567    \n",
      "Epoch 22/30\n",
      "101/100 [==============================] - 45s - loss: 1.0928 - acc: 0.6554    \n",
      "Epoch 23/30\n",
      "101/100 [==============================] - 48s - loss: 1.0431 - acc: 0.6740    \n",
      "Epoch 24/30\n",
      "101/100 [==============================] - 45s - loss: 1.0430 - acc: 0.6672    \n",
      "Epoch 25/30\n",
      "101/100 [==============================] - 45s - loss: 1.0141 - acc: 0.6843    \n",
      "Epoch 26/30\n",
      "101/100 [==============================] - 45s - loss: 0.9919 - acc: 0.6864    \n",
      "Epoch 27/30\n",
      "101/100 [==============================] - 45s - loss: 0.9884 - acc: 0.6861    \n",
      "Epoch 28/30\n",
      "101/100 [==============================] - 45s - loss: 0.9761 - acc: 0.6864    \n",
      "Epoch 29/30\n",
      "101/100 [==============================] - 47s - loss: 0.9742 - acc: 0.7035    \n",
      "Epoch 30/30\n",
      "101/100 [==============================] - 45s - loss: 0.9331 - acc: 0.7033    \n"
     ]
    }
   ],
   "source": [
    "history_tl = model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=NB_EPOCHS,\n",
    "    steps_per_epoch=x_train.shape[0]/BAT_SIZE,     \n",
    "    class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "     layer.trainable = False\n",
    "for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "     layer.trainable = True\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., class_weight=\"auto\", steps_per_epoch=100, epochs=30)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 87s - loss: 0.9140 - acc: 0.7114    \n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 80s - loss: 0.6263 - acc: 0.8052    \n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 80s - loss: 0.5453 - acc: 0.8277    \n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 80s - loss: 0.4884 - acc: 0.8484    \n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 80s - loss: 0.4325 - acc: 0.8653    \n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 80s - loss: 0.4272 - acc: 0.8668    \n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 80s - loss: 0.3763 - acc: 0.8921    \n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 82s - loss: 0.3757 - acc: 0.8849    \n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 87s - loss: 0.3415 - acc: 0.8886    \n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 80s - loss: 0.3120 - acc: 0.9058    \n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 80s - loss: 0.2920 - acc: 0.9091    \n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 80s - loss: 0.2946 - acc: 0.9137    \n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 80s - loss: 0.2602 - acc: 0.9220    \n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 80s - loss: 0.2583 - acc: 0.9224    \n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 80s - loss: 0.2399 - acc: 0.9311    \n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 80s - loss: 0.2084 - acc: 0.9462    \n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 80s - loss: 0.2136 - acc: 0.9362    \n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 80s - loss: 0.1927 - acc: 0.9459    \n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 80s - loss: 0.1970 - acc: 0.9427    \n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 80s - loss: 0.1834 - acc: 0.9448    \n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 80s - loss: 0.1765 - acc: 0.9528    \n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 80s - loss: 0.1601 - acc: 0.9543    \n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 80s - loss: 0.1688 - acc: 0.9515    \n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 80s - loss: 0.1632 - acc: 0.9547    \n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 80s - loss: 0.1448 - acc: 0.9597    \n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 80s - loss: 0.1274 - acc: 0.9675    \n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 80s - loss: 0.1310 - acc: 0.9691    \n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 80s - loss: 0.1264 - acc: 0.9681    \n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 80s - loss: 0.1169 - acc: 0.9725    \n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 80s - loss: 0.1117 - acc: 0.9731    \n"
     ]
    }
   ],
   "source": [
    "history_ft = model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=NB_EPOCHS,\n",
    "    steps_per_epoch=x_train.shape[0]// BAT_SIZE,    \n",
    "    class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## predict test data\n",
    "predictions = model.predict(preprocess_input(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 10, 23, ..., 21, 10, 13])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get labels\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "pred_labels = le.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['candy', 'honey', 'vinegar', ..., 'tea', 'honey', 'milk'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make submission\n",
    "sub = pd.DataFrame({'image_id':test.image_id, 'label':pred_labels})\n",
    "sub.to_csv('sub_Iv5.csv', index=False) ##70 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candy          134\n",
       "coffee         116\n",
       "juice          110\n",
       "chocolate      109\n",
       "water          102\n",
       "tea            100\n",
       "cereal          99\n",
       "jam             86\n",
       "spices          74\n",
       "chips           69\n",
       "milk            65\n",
       "honey           62\n",
       "tomatosauce     58\n",
       "nuts            57\n",
       "rice            56\n",
       "vinegar         55\n",
       "soda            54\n",
       "cake            52\n",
       "beans           50\n",
       "oil             46\n",
       "pasta           45\n",
       "fish            41\n",
       "flour           32\n",
       "sugar           31\n",
       "corn            29\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
